{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio Fingerprinting \n",
    "\n",
    "\n",
    "Implementing Shazam's' Algorithm on the yfcc/yli dataset. \n",
    "Created a database of 2116 audio files and created a query of 50 audio samples.\n",
    "Created a 3D matrix of snippets and noise, having the rows as the indicator of the song number and the columns as the snippet duration( 1 sec, 5 sec, 10 sec, 15 sec, 30 sec)\n",
    "The 3rd dimension indicates the noise added( 0db snr, 5db,10,20 db).\n",
    "\n",
    "MAP was used to test the inital hypothesis. \n",
    "The results are as follows:-\n",
    "    \n",
    "    X axis Second Snippets\n",
    "    Y axis Noise Snippets\n",
    "    \n",
    "    \n",
    "    MAP values \n",
    "    \n",
    "    0.1701 0.6584 0.7669 0.8647 0.9488\n",
    "    0.1946 0.7176 0.8107 0.8955 1.0000\n",
    "    0.1714 0.7794 0.9240 0.9768 1.0000\n",
    "    0.2262 0.8779 0.9542 1.0000 1.0000\n",
    "    \n",
    "    \n",
    "Now I am trying to tweak the parameters of the algorithm to determine which of the values suit our method best.\n",
    "\n",
    "_____________________________________________________\n",
    "\n",
    "There are the parameters I found that are worthy of tweaking:-\n",
    "    \n",
    "    1) Target Hashes per second-> N -> which is initially taken to be 10 while creating the database and 20 while querying the audio.\n",
    "       Increasing N could result in increasing the number of landmarks and hence more accuracy.\n",
    "        \n",
    "    2) Decreasing the spreading width of the masking skirt-> f_sd -> the peaks that we obtain from the spectrogram and then convolved with the f_sd parameter\n",
    "       Decreasing this parameter would increase the number of landmarks and hence the accuracy.\n",
    "        \n",
    "    3) Decay rate of the masking skirt-> depends on N= the target hashes per second.\n",
    "    \n",
    "    4) Maximum number of peaks allowed per second-> Generally this parameter is not easily reached as I checked by testing on a few samples\n",
    "       \n",
    "    5) Number of pairs formed with each peak-> Most promising factor that could result in increase in performance.\n",
    "    \n",
    "    6) window size 64ms and 512 pt FFT. Generally all the papers use this as a standard and hence better not to change it.\n",
    "    \n",
    "    7) Number of time frequency peaks found per second --> Increasing this theoretically should increase the accuracy.\n",
    "    \n",
    " ____________________________________________________________________________________________________________________________\n",
    "Progress Till Date\n",
    " I have been working to get the code up and running and suiting to out needs.Dan's code needed some major change and hence we had to modify some parts of the code:-\n",
    "    1) The funciton landmark2hash had to modified to suit the task of dividing the jobs to differnt machines. We had to introdoce another column in the HashTable and HashTable Counts to account for the unsync between the commands received from the different machines\n",
    "    2) Had to write functionise the code so that just a single run could enable the running of entire job of creating the database as well as the queries.\n",
    "    3) Had to customise the code to suit the changing of parameters from the main function itself.\n",
    "    4) Wrote 2 bash scripts to so that the job gets done faster ( on a cluster).\n",
    "    \n",
    "Description of the Query Code\n",
    "\n",
    "function [Q,SR] = gen_random_queries(IDs,Seed)\n",
    "%IDs=C;\n",
    "nIDs = length(IDs);\n",
    "\n",
    "%prepend = '';\n",
    "postpend = '';\n",
    "\n",
    "SR = 0;\n",
    "\n",
    "if nargin > 3\n",
    "  rns = RandStream.create('mt19937ar','seed',Seed);\n",
    "  RandStream.setDefaultStream(rns);\n",
    "end\n",
    "\n",
    "for i = 1:length(IDs)\n",
    "  %i=1;\n",
    "  id = IDs{i};\n",
    "  fname = ['/share/workhorse2/pmanocha/wav_audio/',id,postpend];\n",
    "  [pth,nm,ext] = fileparts(fname);\n",
    "  if strcmp(ext,'.wav') == 1\n",
    "    [d,sr] = audioread(fname);\n",
    "    time=length(d)/sr ;\n",
    "    %disp(time);\n",
    "  end\n",
    "  if size(d,2) == 2\n",
    "    % convert to mono if stereo\n",
    "    d = mean(d,2);\n",
    "  end\n",
    "  % choose random excerpt\n",
    "  ld = length(d);\n",
    "  snippets=[1,5,10,15,30];\n",
    "  snr=[0,5,10,20];\n",
    "  for j=1:5\n",
    "%j=3;\n",
    "  qlen = round(snippets(j)* sr);\n",
    "  disp(i);\n",
    "    if(ld-qlen)>=0\n",
    "    sp = round((ld - qlen)*rand(1));\n",
    "    %disp(j);\n",
    "    %Q{i,j} = d(sp + [1:qlen]);\n",
    "        for k=1:4\n",
    "            %k=1;\n",
    "            Npts = length(d(sp + [1:qlen])); % Number of input time samples\n",
    "            Noise = randn(1,Npts); % Generate initial noise; mean zero, variance one\n",
    "            Noise_Power=sum(abs(Noise).*abs(Noise));\n",
    "            Signal_Power = sum(abs(d(sp + [1:qlen])).*abs(d(sp + [1:qlen])));\n",
    "            K = (Signal_Power/Noise_Power)*10^(-snr(k)/10);\n",
    "            New_Noise = sqrt(K)*Noise;\n",
    "            Noise_Power=sum(abs(New_Noise).*abs(New_Noise));\n",
    "            Initial_SNR = 10*(log10(Signal_Power./Noise_Power));\n",
    "            %disp(Initial_SNR)\n",
    "            Q{i,j,k}=d(sp + [1:qlen]) + New_Noise';\n",
    "            %Z= d(sp + [1:qlen]) + New_Noise';\n",
    "            %awgn(d(sp + [1:qlen]),snr(k));     \n",
    "        end\n",
    "    end\n",
    " \n",
    "  end\n",
    "  if SR == 0\n",
    "    SR = sr;\n",
    "  elseif SR ~= sr\n",
    "    error(['File ',fname,' has sr ',num2str(sr),' not ', num2str(SR)]);\n",
    "  end\n",
    "  %save('snippets&noise_try2.mat','Q');\n",
    "end\n",
    "\n",
    "This code takes in the table with the file names and creates a 50 x "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
