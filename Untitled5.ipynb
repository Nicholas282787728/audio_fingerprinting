{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio Fingerprinting \n",
    "\n",
    "\n",
    "Implementing Shazam's' Algorithm on the yfcc/yli dataset. \n",
    "\n",
    "The YLI/YFCC dataset is available at \n",
    "https://webscope.sandbox.yahoo.com/catalog.php?datatype=i&did=67\n",
    "    This contains around 99.2 million photos and 0.8 million videos all collected from flickr. You would get nearly 14GB worth of csv files in which the links for the file are embedded in the metadata.\n",
    "    As I had to extract only the .mp4 files , I wrote a python script to check only the .mp4 files and download them in the repository.\n",
    "    Here is the python code.\n",
    "\n",
    "import urllib2\n",
    "import os.path\n",
    "import subprocess\n",
    "\n",
    "def split_str(s, n):\n",
    "    length = len(s)\n",
    "    return [ s[i:i+n] for i in range(0, length, n) ]\n",
    "\n",
    "def img_download(url, filename):\n",
    "    img = urllib2.urlopen(url)\n",
    "    fout = open(filename, 'wb')\n",
    "    fout.write(img.read())\n",
    "    img.close()\n",
    "    fout.close()\n",
    "\n",
    "fin = open('/share/workhorse2/pmanocha/yfcc100m_dataset.csv')\n",
    "imgdir = '/share/workhorse2/pmanocha/video_all_test_13'\n",
    "\n",
    "print 'Start downloading YFCC100M dataset...'\n",
    "for line in fin:\n",
    "    line_split = line.strip().split('\\t')\n",
    "    line_num = int(line_split[0])\n",
    "    photo_id = int(line_split[1])    # photo id\n",
    "    photo_url = line_split[16]    # photo URL for downloading\n",
    "    photo_ext = os.path.splitext(photo_url)[1]\n",
    "    if photo_ext=='':\n",
    "        photo_ext = '.mp4'\n",
    "    if photo_ext == '.mp4':\n",
    "        split_photo_id = split_str(str(photo_id), 3)\n",
    "        photo_dir = os.path.join(imgdir, split_photo_id[0], split_photo_id[1])\n",
    "        photo_name = os.path.join(imgdir,str(photo_id)+photo_ext)\n",
    "        if os.path.isfile(photo_name) and os.path.getsize(photo_name):\n",
    "            print 'Line %d, id %d, skipped' % (line_num, photo_id)\n",
    "            continue    # avoid duplicate downloading\n",
    "        print 'Line %d, id %d, download' % (line_num, photo_id)\n",
    "        try:\n",
    "            subprocess.call('mkdir -p ' + photo_dir, shell=True)\n",
    "            print (photo_url,photo_name)\n",
    "            img_download(photo_url,photo_name)\n",
    "        except:\n",
    "            print 'Failed'\n",
    "            \n",
    "    After you download the files, you would need a .mp4 to .wav file conversion as we only need the audio part of the video. \n",
    "    Here is the code that I wrote that converts it to a mono audio, sampled at 16KHz using ffmpeg.\n",
    "    \n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "#from tqdm import tqdm\n",
    "from subprocess import call     \n",
    "from sys import argv            \n",
    "import os                       \n",
    "\n",
    "def check_file_exists(directory, filename, extension):\n",
    "    path = directory + \"/\" + filename + extension\n",
    "    return os.path.isfile(path)\n",
    "\n",
    "def main(indir, outdir):\n",
    "\n",
    "\n",
    "    try:\n",
    "        # check specified folders exist\n",
    "        if not os.path.exists(indir):\n",
    "            exit(\"Error: Input directory \\'\" + indir + \"\\' does not exist. (try prepending './')\")\n",
    "        if not os.path.exists(outdir):\n",
    "            exit(\"Error: Output directory \\'\" + outdir + \"\\' does not exist.\")\n",
    "        if not os.access(outdir, os.W_OK):\n",
    "            exit(\"Error: Output directory \\'\" + outdir + \"\\' is not writeable.\")\n",
    "\n",
    "        print \"[%s/*.mp4] --> [%s/*.wav]\" % (indir, outdir)\n",
    "        files = [] # files for exporting\n",
    "            \n",
    "        # get a list of all convertible files in the input directory\n",
    "        filelist = [ f for f in os.listdir(indir) if f.endswith(\".mp4\") ]\n",
    "        for path in filelist:\n",
    "            basename = os.path.basename(path) \n",
    "            filename = os.path.splitext(basename)[0]\n",
    "            files.append(filename)\n",
    "        # remove files that have already been outputted from the list\n",
    "        files[:] = [f for f in files if not check_file_exists(outdir, f, \".wav\")]\n",
    "    except OSError as e:\n",
    "        exit(e)\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        exit(\"Could not find any files to convert that have not already been converted.\")\n",
    "\n",
    "    # convert all unconverted files\n",
    "    for filename in files:\n",
    "        print \"-- converting %s.mp4 to %s.wav --\" % (indir + \"/\" + filename, outdir + \"/\" + filename)\n",
    "        #setenv LD_LIBRARY_PATH /home/bhiksha/library/ffmpeg/lib\n",
    "        output_audio_file=  '/share/workhorse2/pmanocha/wav_audio/' + filename + '.wav'\n",
    "        input_video_file= indir + '/' + filename + '.mp4' \n",
    "        #temp_audio_file = output_audio_file.split('.wav')[0] + '_temp.wav'\n",
    "        cmdstring = \"ffmpeg -loglevel panic -i %s -ac 1 -ar 16000 %s\" %(input_video_file,output_audio_file)\n",
    "        os.system(cmdstring)\n",
    "        #subprocess.call(cmdstring, shell=True)\n",
    "\n",
    "#        cmdstring1 = \"sox %s -G -b 16 -r 16000 %s\" %(temp_audio_file,output_audio_file)\n",
    "#        os.system(cmdstring1)\n",
    "#        cmdstring2 = \"rm -rf %s\" %(temp_audio_file)\n",
    "#        os.system(cmdstring2) \n",
    "        \n",
    "        #call([\"mplayer\", \"-novideo\", \"-nocorrect-pts\", \"-ao\", \"pcm:waveheader\", indir + \"/\" + filename + \".mp4\"])\n",
    "        #call([\"lame\", \"-h\", \"-b\", \"192\", \"audiodump.wav\", outdir + \"/\" + filename + \".mp3\"])\n",
    "        #os.remove(\"audiodump.wav\")\n",
    "\n",
    "# set the default directories and try to get input directories\n",
    "args = [\".\", \".\"]\n",
    "for i in range(1, min(len(argv), 3)):\n",
    "    args[i - 1] = argv[i]\n",
    "\n",
    "# if only input directory is set, make the output directory the same\n",
    "if len(argv) == 2:\n",
    "    args[1] = args[0]\n",
    "\n",
    "main(args[0], args[1]) \n",
    "\n",
    "\n",
    "After getting the files in the correct format, we use start implementing the Shazam's' algorithm. Some part of the code is directly used from Dan Ellis's' implementation \n",
    "Shazam. Some of the other code that I have written to suit our job is explained below.\n",
    "\n",
    "I edited the function add_tracks.m which was already there to accomodate the differnt parameters that we would be changing in the implementation. Also to make the entire program scalable to large datasets,\n",
    "I had to make it eligible for parallel processing. Hence, I added an extra column in the hash table to keep track of the song numbers as different nodes compute at different times.\n",
    "One more important factor to note is that, Dan took the number of hashes per second parameter while creating the database to be 10 wheras he took the same parameter to be 20 while querying the audio.\n",
    "I took this as a parameter and varied it to find the best possible value.\n",
    "\n",
    "Then I completely wrote down the code for gen_random_queries.m which takes in an audio file and creates random snippets and adds noise to the audio file. What it does it, for a specific audio, it creates 4 random snippets of 1,5,10,15,30 seconds( whereever possible)\n",
    "and then at each snippt, adds noise (0 db,5 db,10 db,20 db). hence for each audio file, we get a 1 x 5 x 4 matrix.\n",
    "\n",
    "Description of the Query Code\n",
    "\n",
    "function [Q,SR] = gen_random_queries(IDs,Seed)\n",
    "%IDs=C;\n",
    "nIDs = length(IDs);\n",
    "\n",
    "%prepend = '';\n",
    "postpend = '';\n",
    "\n",
    "SR = 0;\n",
    "\n",
    "if nargin > 3\n",
    "  rns = RandStream.create('mt19937ar','seed',Seed);\n",
    "  RandStream.setDefaultStream(rns);\n",
    "end\n",
    "\n",
    "for i = 1:length(IDs)\n",
    "  %i=1;\n",
    "  id = IDs{i};\n",
    "  fname = ['/share/workhorse2/pmanocha/wav_audio/',id,postpend];\n",
    "  [pth,nm,ext] = fileparts(fname);\n",
    "  if strcmp(ext,'.wav') == 1\n",
    "    [d,sr] = audioread(fname);\n",
    "    time=length(d)/sr ;\n",
    "    %disp(time);\n",
    "  end\n",
    "  if size(d,2) == 2\n",
    "    % convert to mono if stereo\n",
    "    d = mean(d,2);\n",
    "  end\n",
    "  % choose random excerpt\n",
    "  ld = length(d);\n",
    "  snippets=[1,5,10,15,30];\n",
    "  snr=[0,5,10,20];\n",
    "  for j=1:5\n",
    "%j=3;\n",
    "  qlen = round(snippets(j)* sr);\n",
    "  disp(i);\n",
    "    if(ld-qlen)>=0\n",
    "    sp = round((ld - qlen)*rand(1));\n",
    "    %disp(j);\n",
    "    %Q{i,j} = d(sp + [1:qlen]);\n",
    "        for k=1:4\n",
    "            %k=1;\n",
    "            Npts = length(d(sp + [1:qlen])); % Number of input time samples\n",
    "            Noise = randn(1,Npts); % Generate initial noise; mean zero, variance one\n",
    "            Noise_Power=sum(abs(Noise).*abs(Noise));\n",
    "            Signal_Power = sum(abs(d(sp + [1:qlen])).*abs(d(sp + [1:qlen])));\n",
    "            K = (Signal_Power/Noise_Power)*10^(-snr(k)/10);\n",
    "            New_Noise = sqrt(K)*Noise;\n",
    "            Noise_Power=sum(abs(New_Noise).*abs(New_Noise));\n",
    "            Initial_SNR = 10*(log10(Signal_Power./Noise_Power));\n",
    "            %disp(Initial_SNR)\n",
    "            Q{i,j,k}=d(sp + [1:qlen]) + New_Noise';\n",
    "            %Z= d(sp + [1:qlen]) + New_Noise';\n",
    "            %awgn(d(sp + [1:qlen]),snr(k));     \n",
    "        end\n",
    "    end\n",
    " \n",
    "  end\n",
    "  if SR == 0\n",
    "    SR = sr;\n",
    "  elseif SR ~= sr\n",
    "    error(['File ',fname,' has sr ',num2str(sr),' not ', num2str(SR)]);\n",
    "  end\n",
    "  %save('snippets&noise_try2.mat','Q');\n",
    "end\n",
    "\n",
    "\n",
    "After obtaining the queries, we wrote down the code for matching the queries with the Hash Table.  For this, I had to create the function match_query.m which takes in the Queries and some of the parameters and gives us the list of the closest and most matched files in the Hash Table.\n",
    "\n",
    "The code is as follows:- \n",
    "       count_AP=zeros(4,5);\n",
    "    count_items=zeros(4,5);\n",
    "    for i=1:50\n",
    "        for j=1:5\n",
    "            for k=1:4\n",
    "                if isempty(Z{i,j,k})==0 &&  all(Z{i,j,k})==1\n",
    "                    %count_items(k,j)=count_items(k,j)+1;\n",
    "                    try\n",
    "                     r=match_query(Z{i,j,k},16000,str2double(stsz),str2double(styp),str2double(maxp));\n",
    "                     count_items(k,j)=count_items(k,j)+1;\n",
    "                     for t=1:size(r,1)\n",
    "                        if r(t,1)==i\n",
    "                            count_AP(k,j)=count_AP(k,j)+ (1./t); \n",
    "                            break\n",
    "                        end  \n",
    "                    end\n",
    "%                     catch\n",
    "%                         disp('An Error occured in the landmarks( no. of landmarks=1')\n",
    "%                         break\n",
    "                    \n",
    "                    \n",
    "                    end\n",
    "                    \n",
    "                end        \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    MAP_right=count_AP ./ count_items;\n",
    "    disp(MAP_right)\n",
    "    \n",
    "    I wrote down the code for calculating MAP as well. It is used in retrival tasks. \n",
    "\n",
    "Created a database of 2116 audio files and created a query of 50 audio samples.\n",
    "Created a 3D matrix of snippets and noise, having the rows as the indicator of the song number and the columns as the snippet duration( 1 sec, 5 sec, 10 sec, 15 sec, 30 sec)\n",
    "The 3rd dimension indicates the noise added( 0db snr, 5db,10,20 db).\n",
    "\n",
    "MAP was used to test the inital hypothesis. \n",
    "The results are as follows:-\n",
    "    \n",
    "    X axis Second Snippets\n",
    "    Y axis Noise Snippets\n",
    "    \n",
    "    \n",
    "    MAP values \n",
    "    \n",
    "    0.1701 0.6584 0.7669 0.8647 0.9488\n",
    "    0.1946 0.7176 0.8107 0.8955 1.0000\n",
    "    0.1714 0.7794 0.9240 0.9768 1.0000\n",
    "    0.2262 0.8779 0.9542 1.0000 1.0000\n",
    "    \n",
    "    \n",
    "Now I am trying to tweak the parameters of the algorithm to determine which of the values suit our method best.\n",
    "\n",
    "_____________________________________________________\n",
    "\n",
    "There are the parameters I found that are worthy of tweaking:-\n",
    "    \n",
    "    1) Target Hashes per second-> N -> which is initially taken to be 10 while creating the database and 20 while querying the audio.\n",
    "       Increasing N could result in increasing the number of landmarks and hence more accuracy.\n",
    "        \n",
    "    2) Decreasing the spreading width of the masking skirt-> f_sd -> the peaks that we obtain from the spectrogram and then convolved with the f_sd parameter\n",
    "       Decreasing this parameter would increase the number of landmarks and hence the accuracy.\n",
    "        \n",
    "    3) Decay rate of the masking skirt-> depends on N= the target hashes per second.\n",
    "    \n",
    "    4) Maximum number of peaks allowed per second-> Generally this parameter is not easily reached as I checked by testing on a few samples\n",
    "       \n",
    "    5) Number of pairs formed with each peak-> Most promising factor that could result in increase in performance.\n",
    "    \n",
    "    6) window size 64ms and 512 pt FFT. Generally all the papers use this as a standard and hence better not to change it.\n",
    "    \n",
    "    7) Number of time frequency peaks found per second --> Increasing this theoretically should increase the accuracy.\n",
    "    \n",
    " ____________________________________________________________________________________________________________________________\n",
    "Progress Till Date\n",
    " I have been working to get the code up and running and suiting to out needs.Dan's code needed some major change and hence we had to modify some parts of the code:-\n",
    "    1) The funciton landmark2hash had to modified to suit the task of dividing the jobs to differnt machines. We had to introdoce another column in the HashTable and HashTable Counts to account for the unsync between the commands received from the different machines\n",
    "    2) Had to write functionise the code so that just a single run could enable the running of entire job of creating the database as well as the queries.\n",
    "    3) Had to customise the code to suit the changing of parameters from the main function itself.\n",
    "    4) Wrote 2 bash scripts to so that the job gets done faster ( on a cluster).\n",
    "_________________________________________________________________\n",
    "06/13/2017\n",
    "Following up on the jobs to be performed on cluster. Saw some weird error on some of the nodes coming up, saying some there is some problem with audioread.m ( matlab's' inbuilt function for reading audio files). I guess it is just a problem of some nodes. I ran it on long with ppn=1 and it now seems to be running fine\n",
    "\n",
    "Have also been reading up on PCA and doing literature survey on usage of PCA and sparse PCA over audio data.\n",
    "_________________________________________________________________________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
